# -*- coding: utf-8 -*-
"""HOUSE RENTING

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ehk7lGxWiJ86G9LiKn0hWEFVGoJ1BdrS
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
df = pd.read_excel("/content/HOUSE RENTING(1).xlsx")
df

#data cleaning process
#step1 removing duplicates
a = df.drop_duplicates()
a

#step2 removing the unwanted columns
b = a.drop(columns='JOB')
b

#step3 handling the empty values
# Check for empty cells
empty_cells = b.isnull().sum()
# Display the count of empty cells for each column
print(empty_cells)

# Replace NaN values in multiple columns with 1
columns_to_replace = ['gym', 'swimming_pool','lift']  # List of columns to replace NaN values

for column in columns_to_replace:
    b.loc[b[column].isna(), column] = 1

# Print the DataFrame after replacement
print(b)

# Check for empty cells
empty_cells = b.isnull().sum()
# Display the count of empty cells for each column
print(empty_cells)

#shape of the dataset
b.shape

#column names
b.columns

#information about the datset
b.info

#describe the dataset
b.describe()



# Assuming your dataset is stored in a DataFrame called 'df'
skewness_dict = {}

# List of columns for which you want to calculate skewness
columns_to_check = ['AGE', 'lift', 'negotiable','negotiable','rent']

for column in columns_to_check:
    skewness = b[column].skew()
    skewness_dict[column] = skewness

print("Skewness for each column:")
for column, skewness in skewness_dict.items():
    print(f"{column}: {skewness}")

# List of columns for which you want to apply the transformation
columns_to_transform = ['AGE', 'lift', 'negotiable','negotiable','rent']

for column in columns_to_transform:
    b[column] = np.log1p(b[column])

#step5 skewness of the dataset
import pandas as pd

# Assuming your dataset is stored in a DataFrame called 'df'
skewness_dict = {}

# List of columns for which you want to calculate skewness
columns_to_check = ['AGE', 'lift', 'negotiable','negotiable','rent']

for column in columns_to_check:
    skewness = b[column].skew()
    skewness_dict[column] = skewness

print("Skewness for each column:")
for column, skewness in skewness_dict.items():
    print(f"{column}: {skewness}")

# Count the number of properties for each lease type
lease_counts = b['lease_type'].value_counts()

# Plotting
plt.figure(figsize=(8, 8))
plt.pie(lease_counts, labels=lease_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Lease Type Distribution')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle
plt.show()

# Plotting
plt.figure(figsize=(10, 6))
b['GENDER'].value_counts().plot(kind='bar')
plt.xlabel('Locality')
plt.ylabel('Count')
plt.title('Count of Houses by Locality')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels
plt.tight_layout()
plt.show()

# Count occurrences of each 'locality' for each 'id'
locality_counts = b.groupby('AGE')['locality'].value_counts().unstack(fill_value=0)

# Plotting
plt.figure(figsize=(10, 6))
locality_counts.plot(kind='bar', stacked=True)
plt.ylabel('Locality')
plt.xlabel('AGE')
plt.title('Count of Localities by ID')
plt.legend(title='Locality', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# Plotting
plt.figure(figsize=(10, 6))

# Scatter plot for gym users
plt.scatter(b['GENDER'],b['gym'], color='blue', label='Gym', alpha=0.5)

# Scatter plot for lift users
plt.scatter(b['GENDER'], b['lift'], color='green', label='Lift', alpha=0.5)

# Scatter plot for swimming pool users
plt.scatter(b['GENDER'], b['swimming_pool'], color='orange', label='Swimming Pool', alpha=0.5)

# Adding labels and title
plt.xlabel('Gender')
plt.ylabel('Usage')
plt.title('Gym, Lift, and Swimming Pool Users by Gender')
plt.legend()

plt.tight_layout()
plt.show()

# Plotting
plt.figure(figsize=(10, 6))

# Counting IDs per locality
locality_counts = b['locality'].value_counts()

# Plotting histogram
locality_counts.hist( color='skyblue')

# Adding labels and title
plt.xlabel('Locality')
plt.ylabel('Number of IDs')
plt.title('Distribution of IDs Across Localities')
plt.grid(linestyle='')
plt.tight_layout()
plt.show()

# Sorting the DataFrame by 'rent'
df_sorted = b.sort_values(by='rent')

# Plotting
plt.figure(figsize=(10, 6))

# Line plot for housing and rent
plt.plot(df_sorted['Housing'], df_sorted['rent'], marker='o', color='pink', linestyle='-')

# Adding labels and title
plt.xlabel('Housing Type')
plt.ylabel('Rent')
plt.title('Relationship between Housing Type and Rent')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

b.columns

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Load your dataset
file_path = '/content/HOUSE RENTING(1).xlsx'
df = pd.read_excel(file_path)

# Assuming 'target_variable' is the column you want to predict
target_variable = input("Enter the name of the target variable: ")

# Assuming 'feature_variables' are the columns you want to use as features
feature_variables = ['AGE', 'gym', 'lift', 'swimming_pool', 'negotiable', 'balconies']

# Filter out rows with missing values in feature variables or target variable
df.dropna(subset=feature_variables + [target_variable], inplace=True)

# Split the dataset into features (X) and target variable (y)
X = df[feature_variables]
y = df[target_variable]

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and fit linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate Mean Squared Error (MSE) as a measure of accuracy
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

# Get user input for prediction
input_data = {}
for column in X.columns:
    value = float(input(f"Enter the value for {column}: "))
    input_data[column] = value

# Make prediction for user input
input_df = pd.DataFrame([input_data])
user_prediction = model.predict(input_df)[0]
print("Predicted " + target_variable + ":", user_prediction)

# Plotting the linear regression graph
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='blue', alpha=0.6, label='Predicted vs Actual')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Perfect Prediction Line')
plt.scatter([user_prediction], [user_prediction], color='red', s=100, label='User Prediction')
plt.xlabel(f"Actual {target_variable}")
plt.ylabel(f"Predicted {target_variable}")
plt.title("Linear Regression: Actual vs Predicted")
plt.legend()
plt.grid(True)
plt.show()

# Calculate and print the accuracy of the model
accuracy = model.score(X_test, y_test)
print("Accuracy:", accuracy)

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Load your dataset
file_path = '/content/HOUSE RENTING(1).xlsx'
df = pd.read_excel(file_path)

# Assuming 'target_variable' is the column you want to predict
target_variable = input("Enter the name of the target variable: ")

# Assuming 'feature_variables' are the columns you want to use as features
feature_variables = ['AGE', 'gym', 'lift', 'swimming_pool', 'negotiable', 'balconies']

# Filter out rows with missing values in feature variables or target variable
df.dropna(subset=feature_variables + [target_variable], inplace=True)

# Split the dataset into features (X) and target variable (y)
X = df[feature_variables]
y = df[target_variable]

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and fit linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate Mean Squared Error (MSE) as a measure of accuracy
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

# Calculate and print the accuracy of the model
accuracy = model.score(X_test, y_test)
print("Accuracy:", accuracy)

# Get user input for prediction
input_data = {}
for column in X.columns:
    value = float(input(f"Enter the value for {column}: "))
    input_data[column] = value

# Make prediction for user input
input_df = pd.DataFrame([input_data])
user_prediction = model.predict(input_df)[0]
print("Predicted " + target_variable + ":", user_prediction)

# Calculate Confusion Matrix
threshold = 0.5  # Set a threshold for binary classification
binary_predictions = [1 if pred > threshold else 0 for pred in y_pred]
binary_test_labels = [1 if label > threshold else 0 for label in y_test]

# Generate confusion matrix
conf_matrix = confusion_matrix(binary_test_labels, binary_predictions)
print("Confusion Matrix:")
print(conf_matrix)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Load your dataset
file_path = '/content/HOUSE RENTING(1).xlsx'
df = pd.read_excel(file_path)

# Assuming 'target_variable' is the column you want to predict
target_variable = input("Enter the name of the target variable: ")

# Assuming 'feature_variables' are the columns you want to use as features
feature_variables = ['AGE', 'gym', 'lift', 'swimming_pool', 'negotiable', 'balconies']

# Filter out rows with missing values in feature variables or target variable
df.dropna(subset=feature_variables + [target_variable], inplace=True)

# Split the dataset into features (X) and target variable (y)
X = df[feature_variables]
y = df[target_variable]

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and fit linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate Mean Squared Error (MSE) as a measure of accuracy
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

# Make prediction for a new input
input_data = {}
for column in X.columns:
    value = float(input(f"Enter the value for {column}: "))
    input_data[column] = value

# Make prediction for user input
input_df = pd.DataFrame([input_data])
user_prediction = model.predict(input_df)[0]
print("Predicted " + target_variable + ":", user_prediction)

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Load your dataset
file_path = '/content/HOUSE RENTING(1).xlsx'
df = pd.read_excel(file_path)

# Assuming 'target_variable' is the column you want to predict
target_variable = 'rent'

# Assuming 'feature_variables' are the columns you want to use as features
feature_variables = ['AGE', 'gym', 'lift', 'swimming_pool', 'negotiable', 'balconies']

# Filter out rows with missing values in feature variables or target variable
df.dropna(subset=feature_variables + [target_variable], inplace=True)

# Split the dataset into features (X) and target variable (y)
X = df[feature_variables]
y = df[target_variable]

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and fit linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Plotting the linear regression graph
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)
plt.xlabel("Actual Rent")
plt.ylabel("Predicted Rent")
plt.title("Linear Regression Plot for Rent")
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression

# Load your dataset
file_path = '/content/HOUSE RENTING(1).xlsx'
df = pd.read_excel(file_path)

# Select the target variable (rent) and another dependent variable of interest
target_variable = 'rent'
dependent_variable = input("Enter the name of the other dependent variable: ")

# Filter out rows with missing values in the selected variables
df.dropna(subset=[target_variable, dependent_variable], inplace=True)

# Prepare the data
X = df[[dependent_variable]]
y = df[target_variable]

# Initialize and fit linear regression model
model = LinearRegression()
model.fit(X, y)

# Predict the target variable
y_pred = model.predict(X)

# Define number of bins and bin edges
num_bins = 10
bin_edges = np.linspace(y.min(), y.max(), num_bins + 1)

# Categorize actual and predicted values into bins
actual_bins = np.digitize(y, bin_edges)
predicted_bins = np.digitize(y_pred, bin_edges)

# Create confusion matrix-like visualization
conf_matrix = pd.crosstab(actual_bins, predicted_bins, rownames=['Actual'], colnames=['Predicted'])

# Plot confusion matrix-like visualization
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Bin')
plt.ylabel('Actual Bin')
plt.title(f'Confusion Matrix-like Visualization for {target_variable} vs {dependent_variable}')
plt.show()